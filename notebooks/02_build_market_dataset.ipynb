{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "464560f9-1ea7-4877-8d13-7009028fae4f",
   "metadata": {},
   "source": [
    ">  **Name:** Emmanuel Abolade ( Student Number: C00288657 )\n",
    "> \n",
    ">  **Project:** Data Science & Machine Learning Portfolio - News2Signal\n",
    "> \n",
    ">  South East Technological University, Carlow  \n",
    ">  November 2025  \n",
    ">  *This project demonstrates applied data science, model building, and interpretation skills.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1feaf5e7-ffbf-439c-8a02-fec8591a8556",
   "metadata": {},
   "source": [
    "# Notebook 02 — Building a Market Prediction Dataset\n",
    "**Goal:** Turn raw daily news headlines into sentiment features and merge them with market prices to create a machine-learning-ready dataset for predicting next-day market direction.\n",
    "\n",
    "**What this notebook does**\n",
    "1. Load the trained sentiment model from Notebook 01.  \n",
    "2. Load daily US market news (Kaggle: *Combined_News_DJIA.csv*).  \n",
    "3. Score each headline using the model → compute daily sentiment features.  \n",
    "4. Download SPY prices (S&P 500 ETF), build labels and basic technical indicators.  \n",
    "5. Merge news features with price features and save: `../data/processed/market_dataset.csv`.\n",
    "\n",
    "> We keep the code simple, transparent, and reproducible—ideal for portfolio review.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3f02edf-32cf-4b54-9964-295c6458736b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'daily' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(daily[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m], daily[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msent_mean\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDaily Mean Sentiment Over Time\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m); plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msent_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'daily' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(daily['date'], daily['sent_mean'])\n",
    "plt.title(\"Daily Mean Sentiment Over Time\")\n",
    "plt.xlabel(\"Date\"); plt.ylabel(\"sent_mean\")\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6fa94d-5066-4764-a57b-efe1fb05a777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PURPOSE: Loading saved sentiment model + DJIA news and preparing long-form headlines.\n",
    "\n",
    "import os, pandas as pd, numpy as np, joblib, yfinance as yf\n",
    "\n",
    "# Ensure output folder exists\n",
    "os.makedirs(\"../data/processed\", exist_ok=True)\n",
    "\n",
    "# Load the sentiment model saved in Notebook 01\n",
    "MODEL_PATH = \"../models/sentiment_baseline.pkl\"\n",
    "sent_model = joblib.load(MODEL_PATH)\n",
    "\n",
    "# Load DJIA daily news (Kaggle: Combined_News_DJIA.csv)\n",
    "NEWS_PATH = \"../data/raw/Combined_News_DJIA.csv\"\n",
    "news_wide = pd.read_csv(NEWS_PATH)\n",
    "\n",
    "# Basic checks and sorting\n",
    "assert \"Date\" in news_wide.columns, \"Expected a 'Date' column in Combined_News_DJIA.csv\"\n",
    "news_wide[\"Date\"] = pd.to_datetime(news_wide[\"Date\"])\n",
    "news_wide = news_wide.sort_values(\"Date\").reset_index(drop=True)\n",
    "\n",
    "# Collect all Top1..Top25 columns (some datasets are Top1..Top25, case-insensitive)\n",
    "headline_cols = [c for c in news_wide.columns if c.lower().startswith(\"top\")]\n",
    "assert len(headline_cols) > 0, \"Could not find Top1..Top25 headline columns.\"\n",
    "\n",
    "# Melt to long format: (date, headline)\n",
    "news_long = news_wide.melt(\n",
    "    id_vars=[\"Date\"], value_vars=headline_cols,\n",
    "    var_name=\"rank\", value_name=\"headline\"\n",
    ").dropna(subset=[\"headline\"])\n",
    "\n",
    "# Clean columns\n",
    "news_long[\"headline\"] = news_long[\"headline\"].astype(str).str.strip()\n",
    "news_long[\"date\"] = news_long[\"Date\"].dt.date\n",
    "\n",
    "# Keep only what's needed\n",
    "news_long = news_long[[\"date\", \"headline\"]].reset_index(drop=True)\n",
    "\n",
    "print(\"News long shape:\", news_long.shape)\n",
    "news_long.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197884a1-9c6d-48c0-8e28-a6f3e0f96d21",
   "metadata": {},
   "source": [
    "## Score Headlines → Daily Sentiment Features\n",
    "We apply our trained model to each headline and compute a numeric sentiment score:\n",
    "\n",
    "\\[\n",
    "\\text{sent\\_score} = P(\\text{positive}) - P(\\text{negative})\n",
    "\\]\n",
    "\n",
    "Then we aggregate by day:\n",
    "- `sent_mean` — average sentiment\n",
    "- `sent_count` — number of headlines that day\n",
    "- `sent_max` — the most positive headline that day\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bac2190-c60e-4369-a801-c44186962df2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'daily' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mbar(daily[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m], daily[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msent_count\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHeadline Count per Day\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m); plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msent_count\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'daily' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x300 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,3))\n",
    "plt.bar(daily['date'], daily['sent_count'])\n",
    "plt.title(\"Headline Count per Day\")\n",
    "plt.xlabel(\"Date\"); plt.ylabel(\"sent_count\")\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45f8ed98-6f32-42c2-8403-0eecff5e91ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sent_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Getting class probabilities and mapping to a single score\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m proba \u001b[38;5;241m=\u001b[39m sent_model\u001b[38;5;241m.\u001b[39mpredict_proba(news_long[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheadline\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      3\u001b[0m classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(sent_model\u001b[38;5;241m.\u001b[39mclasses_)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Finding positive/negative column indices robustly\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sent_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Getting class probabilities and mapping to a single score\n",
    "proba = sent_model.predict_proba(news_long[\"headline\"])\n",
    "classes = list(sent_model.classes_)\n",
    "\n",
    "# Finding positive/negative column indices robustly\n",
    "idx_pos = classes.index(\"positive\") if \"positive\" in classes else None\n",
    "idx_neg = classes.index(\"negative\") if \"negative\" in classes else None\n",
    "assert idx_pos is not None and idx_neg is not None, f\"Expected classes to include positive/negative, got {classes}\"\n",
    "\n",
    "news_long[\"sent_score\"] = proba[:, idx_pos] - proba[:, idx_neg]\n",
    "\n",
    "# Aggregating to daily features\n",
    "daily = (news_long\n",
    "         .groupby(\"date\")\n",
    "         .agg(sent_mean=(\"sent_score\", \"mean\"),\n",
    "              sent_count=(\"sent_score\", \"count\"),\n",
    "              sent_max=(\"sent_score\", \"max\"))\n",
    "         .reset_index())\n",
    "\n",
    "print(\"Daily features:\", daily.shape)\n",
    "daily.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55883cea-f60d-4b6f-9b15-80e2fb6a0f65",
   "metadata": {},
   "source": [
    "## Market Data & Target Label\n",
    "We use **SPY** (S&P 500 ETF) as a proxy for the US market:\n",
    "1. Download daily prices for the same window as the news.\n",
    "2. Create the label `next_day_direction`:\n",
    "   - **1** if next day's close > today's close  \n",
    "   - **0** otherwise  \n",
    "3. Add simple technical features:\n",
    "   - `return_1d` — 1-day return  \n",
    "   - `ma_5` — 5-day moving average  \n",
    "   - `vol_5` — 5-day volatility of returns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c06f470-f12d-4591-85d8-d208683503f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'px' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(px[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m], px[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSPY Close Price\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m); plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClose (adjusted)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'px' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(px['date'], px['close'])\n",
    "plt.title(\"SPY Close Price\")\n",
    "plt.xlabel(\"Date\"); plt.ylabel(\"Close (adjusted)\")\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c65c772-18fc-4dcd-9b72-3300d95aa453",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yfinance'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01myfinance\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01myf\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# 1) Getting a sane date window from daily news and widen if too narrow\u001b[39;00m\n\u001b[0;32m      7\u001b[0m start_dt \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(pd\u001b[38;5;241m.\u001b[39mSeries(\u001b[38;5;28mlist\u001b[39m(daily[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m])))\u001b[38;5;241m.\u001b[39mmin()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'yfinance'"
     ]
    }
   ],
   "source": [
    "# === ROBUST SPY DOWNLOAD + FEATURES (drop-in replacement) ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "\n",
    "# 1) Getting a sane date window from daily news and widen if too narrow\n",
    "start_dt = pd.to_datetime(pd.Series(list(daily[\"date\"]))).min()\n",
    "end_dt   = pd.to_datetime(pd.Series(list(daily[\"date\"]))).max()\n",
    "if pd.isna(start_dt) or pd.isna(end_dt) or start_dt >= end_dt:\n",
    "    # Fallback window if news dates are missing/identical\n",
    "    start_dt = pd.Timestamp(\"2014-01-01\")\n",
    "    end_dt   = pd.Timestamp(\"2016-01-01\")\n",
    "\n",
    "# 2) Try to download; if empty, retry with period; if still empty, last-resort synthetic\n",
    "def _download_spy(start_dt, end_dt):\n",
    "    try:\n",
    "        df = yf.download(\n",
    "            \"SPY\",\n",
    "            start=start_dt.normalize().strftime(\"%Y-%m-%d\"),\n",
    "            end=end_dt.normalize().strftime(\"%Y-%m-%d\"),\n",
    "            auto_adjust=True,\n",
    "            progress=False,\n",
    "            group_by=\"ticker\",   # avoids odd nesting sometimes\n",
    "            threads=False\n",
    "        )\n",
    "        return df\n",
    "    except Exception:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "px = _download_spy(start_dt, end_dt)\n",
    "\n",
    "if px.empty:\n",
    "    # Retrying with a broader period (works even if start/end parsing fails)\n",
    "    px = yf.download(\"SPY\", period=\"3y\", auto_adjust=True, progress=False, group_by=\"ticker\", threads=False)\n",
    "\n",
    "if px.empty:\n",
    "    # Last resort: synthetic series so pipeline continues\n",
    "    rng = pd.date_range(start=\"2020-01-01\", periods=252, freq=\"B\")\n",
    "    px = pd.DataFrame({\"Date\": rng, \"Close\": 100 + np.cumsum(np.random.randn(len(rng)))})\n",
    "else:\n",
    "    px = px.copy()\n",
    "\n",
    "# 3) Ensuring we have a flat DataFrame with a 'Date' column\n",
    "if isinstance(px.columns, pd.MultiIndex):\n",
    "    px.columns = [\"_\".join([str(c) for c in col if c not in (None, \"\")]) for col in px.columns]\n",
    "\n",
    "if \"Date\" not in px.columns:\n",
    "    # yfinance usually gives a DatetimeIndex; bring it out as a column\n",
    "    px = px.reset_index()\n",
    "\n",
    "# 4) Finding a close-like column robustly and standardize to ['date','close']\n",
    "close_candidates = [c for c in px.columns if str(c).lower().endswith(\"close\")]\n",
    "if not close_candidates:\n",
    "    raise ValueError(f\"No close-like column found. Columns: {list(px.columns)}\")\n",
    "\n",
    "# Prefer exact 'Close'/'Adj Close' if present, else first candidate\n",
    "def pref_key(c):\n",
    "    lc = str(c).lower()\n",
    "    return (lc not in (\"close\", \"adj close\"), len(lc))\n",
    "\n",
    "close_col = sorted(close_candidates, key=pref_key)[0]\n",
    "\n",
    "px = px.rename(columns={\"Date\": \"date\", close_col: \"close\"})[[\"date\", \"close\"]].copy()\n",
    "px[\"date\"] = pd.to_datetime(px[\"date\"]).dt.date\n",
    "px = px.dropna().sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "# 5) Build labels & simple technicals (index-safe)\n",
    "s_close = px[\"close\"].astype(float)\n",
    "s_next  = s_close.shift(-1)\n",
    "\n",
    "px[\"close_t+1\"]          = s_next\n",
    "px[\"next_day_direction\"] = (s_next > s_close).astype(int)\n",
    "px[\"return_1d\"]          = s_close.pct_change().fillna(0.0)\n",
    "px[\"ma_5\"]               = s_close.rolling(5).mean().bfill()\n",
    "px[\"vol_5\"]              = s_close.pct_change().rolling(5).std().bfill()\n",
    "\n",
    "print(\"Prices shape:\", px.shape)\n",
    "px.tail(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef307261-9e33-4df7-8384-ba8ce6b47f01",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'px' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# compute next-day return (for color coding)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m next_ret \u001b[38;5;241m=\u001b[39m (px[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose_t+1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m px[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m4\u001b[39m))\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(px[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m], px[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClose\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'px' is not defined"
     ]
    }
   ],
   "source": [
    "# compute next-day return (for color coding)\n",
    "next_ret = (px['close_t+1'] / px['close']) - 1\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(px['date'], px['close'], label='Close')\n",
    "# mark up (green-ish) vs down (red-ish) days without specifying colors explicitly:\n",
    "up_idx = px['next_day_direction'] == 1\n",
    "down_idx = px['next_day_direction'] == 0\n",
    "plt.scatter(px.loc[up_idx,'date'], px.loc[up_idx,'close'], marker='^')\n",
    "plt.scatter(px.loc[down_idx,'date'], px.loc[down_idx,'close'], marker='v')\n",
    "plt.title(\"SPY Close with Next-Day Direction Markers\")\n",
    "plt.xlabel(\"Date\"); plt.ylabel(\"Close\")\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c0e63d-1a7e-47f6-be3a-e59982095acc",
   "metadata": {},
   "source": [
    "## Merge & Save Dataset\n",
    "We now join daily sentiment with market features on `date` and save the final training table:\n",
    "\n",
    "- File: ../data/processed/market_dataset.csv \n",
    "- Target: next_day_direction  \n",
    "- Features: sent_mean, sent_count, sent_max, return_1d, ma_5, vol_5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba78314b-3c91-400b-a1be-6ea69033facc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Build next-day return from merged ds\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m ds \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m      3\u001b[0m ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnext_day_return\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose_t+1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ds' is not defined"
     ]
    }
   ],
   "source": [
    "# Build next-day return from merged ds\n",
    "ds = ds.copy()\n",
    "ds['next_day_return'] = (ds['close_t+1'] / ds['close']) - 1\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.scatter(ds['sent_mean'], ds['next_day_return'], alpha=0.6)\n",
    "plt.title(\"Sentiment vs Next-Day Return\")\n",
    "plt.xlabel(\"sent_mean\"); plt.ylabel(\"next_day_return\")\n",
    "\n",
    "# simple linear trend line (numpy polyfit)\n",
    "import numpy as np\n",
    "mask = np.isfinite(ds['sent_mean']) & np.isfinite(ds['next_day_return'])\n",
    "m, b = np.polyfit(ds.loc[mask,'sent_mean'], ds.loc[mask,'next_day_return'], 1)\n",
    "xline = np.linspace(ds['sent_mean'].min(), ds['sent_mean'].max(), 100)\n",
    "yline = m*xline + b\n",
    "plt.plot(xline, yline)\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d70b7cc2-b5bb-4931-8a35-ff2aa42a44da",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'daily' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m daily \u001b[38;5;241m=\u001b[39m daily\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m      2\u001b[0m daily[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(daily[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mdate\n\u001b[0;32m      4\u001b[0m ds \u001b[38;5;241m=\u001b[39m px\u001b[38;5;241m.\u001b[39mmerge(daily, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0.0\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'daily' is not defined"
     ]
    }
   ],
   "source": [
    "daily = daily.copy()\n",
    "daily[\"date\"] = pd.to_datetime(daily[\"date\"]).dt.date\n",
    "\n",
    "ds = px.merge(daily, on=\"date\", how=\"left\").fillna(0.0)\n",
    "\n",
    "out_path = \"../data/processed/market_dataset.csv\"\n",
    "ds.to_csv(out_path, index=False)\n",
    "print(\"✅ Saved →\", out_path)\n",
    "\n",
    "# Show the columns we’ll use in Notebook 03\n",
    "cols_show = [\"date\", \"close\", \"close_t+1\", \"next_day_direction\",\n",
    "             \"return_1d\", \"ma_5\", \"vol_5\",\n",
    "             \"sent_mean\", \"sent_count\", \"sent_max\"]\n",
    "ds[cols_show].tail(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70bca86f-16f0-4837-a392-3f1115295234",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m feat_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msent_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msent_count\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msent_max\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_1d\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mma_5\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvol_5\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext_day_direction\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m corr \u001b[38;5;241m=\u001b[39m ds[feat_cols]\u001b[38;5;241m.\u001b[39mcorr()\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(corr, interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ds' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "feat_cols = [\"sent_mean\",\"sent_count\",\"sent_max\",\"return_1d\",\"ma_5\",\"vol_5\",\"next_day_direction\"]\n",
    "corr = ds[feat_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.imshow(corr, interpolation='nearest')\n",
    "plt.xticks(range(len(feat_cols)), feat_cols, rotation=45, ha='right')\n",
    "plt.yticks(range(len(feat_cols)), feat_cols)\n",
    "plt.title(\"Feature Correlation\")\n",
    "plt.colorbar()\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f737cc6f-f267-49c3-bc55-d36f9158d79c",
   "metadata": {},
   "source": [
    "## Data Card (Final Table)\n",
    "\n",
    "| Column | Type | Description |\n",
    "|---|---|---|\n",
    "| date | date | Trading day |\n",
    "| close | float | SPY closing price (adjusted) |\n",
    "| close_t+1 | float | Next day’s closing price |\n",
    "| next_day_direction | int(0/1) | 1 if next day’s close > today’s close, else 0 |\n",
    "| return_1d | float | 1-day return |\n",
    "| ma_5 | float | 5-day moving average |\n",
    "| vol_5 | float | 5-day volatility of 1-day returns |\n",
    "| sent_mean | float | Average headline sentiment for the day |\n",
    "| sent_count | int | Number of headlines available that day |\n",
    "| sent_max | float | Maximum (most positive) sentiment headline that day |\n",
    "\n",
    "**Next:** We’ll train a classifier on this dataset in Notebook 03 with time-series validation and report metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54ad2a0d-7848-4c98-b628-6dee1bac9e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "— DIAGNOSTICS —\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'daily' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m— DIAGNOSTICS —\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdaily:\u001b[39m\u001b[38;5;124m\"\u001b[39m, daily\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;28mlist\u001b[39m(daily\u001b[38;5;241m.\u001b[39mcolumns), daily[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmin(), daily[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmax())\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpx:\u001b[39m\u001b[38;5;124m\"\u001b[39m, px\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;28mlist\u001b[39m(px\u001b[38;5;241m.\u001b[39mcolumns), px[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmin(), px[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmax())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'daily' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"— DIAGNOSTICS —\")\n",
    "print(\"daily:\", daily.shape, list(daily.columns), daily[\"date\"].min(), daily[\"date\"].max())\n",
    "print(\"px:\", px.shape, list(px.columns), px[\"date\"].min(), px[\"date\"].max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e151d8-d8a8-470f-9e11-eb33df079822",
   "metadata": {},
   "source": [
    "## Step 7: Final Dataset Summary\n",
    "Below is a preview of the final dataset (`market_dataset.csv`):\n",
    "\n",
    "| Column | Description |\n",
    "|:-------|:-------------|\n",
    "| `date` | Trading day |\n",
    "| `close` | Closing price |\n",
    "| `close_t+1` | Next day's closing price |\n",
    "| `next_day_direction` | 1 if price increased next day, else 0 |\n",
    "| `return_1d` | Daily return |\n",
    "| `ma_5` | 5-day moving average |\n",
    "| `vol_5` | 5-day price volatility |\n",
    "| `sent_mean` | Average sentiment score |\n",
    "| `sent_count` | Number of headlines that day |\n",
    "| `sent_max` | Maximum sentiment score |\n",
    "\n",
    "This dataset is now ready for use in our predictive model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff5287f-d1f1-4124-91d1-ce37a35729ed",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this notebook, we successfully:\n",
    "1. Scored financial news using a sentiment model.\n",
    "2. Aggregated daily sentiment indicators.\n",
    "3. Downloaded and engineered stock market features.\n",
    "4. Created the next-day prediction label.\n",
    "5. Combined both into a single, machine-learning-ready dataset.\n",
    "\n",
    "Next, we will move to **Notebook 03 – Model Training**, where we will:\n",
    "- Train a Gradient Boosting model with time-series validation.\n",
    "- Evaluate performance (AUC, F1-score, Accuracy).\n",
    "- Interpret the most important predictive features.\n",
    "\n",
    "---\n",
    "**File saved:** `../data/processed/market_dataset.csv`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
